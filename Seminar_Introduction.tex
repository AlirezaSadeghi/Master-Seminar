\section{مقدمه}\label{intro}
برای بیشتر افراد، مشاهده‌ی یک ویدئو‌ی کوتاه و توصیف محتوی آن، کاری ساده است. اما برای رایانه‌ها، استخراج مفاهیم از پیکسل‌های ویدئو و ایجاد توصیفی به زبان‌طبیعی یک امر بسیار پیچیده‌ است. 
مخلوط کردن پردازش‌زبان‌طبیعی\LTRfootnote{Natural‌Language Processing} با بینایی‌ماشین 
\LTRfootnote{Computer Vision}
جهت ایجاد توصیف‌هایی به زبان انگلیسی از داده‌های تصویری، یکی از زمینه‌های فعال پژوهش در زمینه‌ی یادگیری ماشین است.
راه‌حل‌های متعددی برای دامنه‌های کوچک که مجموعه‌ی کوچکی از فعالیت‌ها را شامل می‌شوند، پیشنهاد شده است، اما توصیف ویدئو‌ها با دامنه‌باز
\LTRfootnote{Open-domain}
، مانند ویدئو‌های یوتیوب\LTRfootnote{Youtube} هنوز یک مسئله‌ی باز است.

بخشی از علل عدم پیشرفت در زمینه‌ی توصیف ویدئو‌های با دامنه‌باز، عدم وجود مجموعه‌دادگان جامع از ویدئو به زبان‌طبیعی است. یکی از دیگر علت‌های این واقعه، نبود مدل‌های مناسبی است که بتوانند ارتباط بین فریم‌های پشت‌سر هم ویدئو و کلمات را ضبط کنند.

پژوهش‌های گذشته، با ثابت در نظر گرفتن ساختار‌های معنایی کوچک، مانند فعل، فاعل و مفعول، به عنوان یک نمایش میانی، سعی در ایجاد جملات زبان‌طبیعی برای ویدئو‌ها داشته‌اند. اما مشخصا استفاده از این نمایش برای مجموعه‌دادها‌ی بزرگ مناسب نیست و منجر به ایجاد جملات بسیار ساده‌تر، و گاها بی‌ربط، نسبت به محتوی ویدئو می‌شود.

در چند‌سال اخیر، مطالعات گسترده‌ای در حوزه یادگیری داده‌های چند‌حالته\LTRfootnote{Multimodal}
صورت گرفته است،  به طور خاص عموم این روش‌ها با استفاده از شبکه‌های عصبی ژرف پیچشی\LTRfootnote{Convolutional Neural Networks}
و 
بازگردنده‌\LTRfootnote{Recurrent Neural Networks}
سعی به ادغام کردن بازنمایشی از فریم‌ها و کلمات زبان‌طبیعی با هم کرده و به نتایج امیدوار‌کننده‌ای رسیده‌اند.
 
 در این نوشتار بر مسئله‌ی ایجاد توصیف برای ویدئو با استفاده از شبکه‌های ژرف تمرکز می‌کنیم؛ به این معنی که داده‌هایی که مایل به ایجاد توصیف برای آن‌ها هستیم، ویدوئوها هستند. البته باید دقت‌ داشت که این مدل‌ها، در حالتی که ویدئو‌ی ورودی تنها متشکل از یک فریم باشد، هم‌عرض مدل‌هایی می‌شوند که روی تصاویر کار می‌کنند. ورودی مدل در زمان آموزش یک یا چند جمله و دنباله‌ای از فریم‌ها است و خروجی مدل یک یا چند جمله به زبان‌طبیعی از محتوی فریم‌ها  است که با جملات ورودی مقایسه‌ می‌شوند.
 در زمان آزمون، ورودی مدل دنباله‌ای از فریم‌هاست و خروجی مدل نیز یک یا چند جمله توصیف‌گر فریم‌ها است.
 
 مباحث در این گزارش به این صورت است: در بخش ۲، صورت‌های مختلفی از مسئله‌ی توصیف ویدئو را بیان کرده و روش‌های پیشین ارائه شده برای حل آن‌ را مرور می‌کنیم. در بخش ۳، یک روش پیشنهادی بیان می‌شود و نتایج عملی آن در بخش ۴ ارائه و با روش‌های دیگر مقایسه می‌شود. بخش ۶ به کارهای آتی، جدول زمان‌بندی پژوهش و جمع‌بندی اختصاص دارد.
 

